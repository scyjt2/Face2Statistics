# Face2Statistics
A comprehensive roadmap to deliver user-friendly, low-cost and effective alternatives for extracting drivers’  statistics. Full paper is accepted by HCII'22.

The WIP version is [here](https://github.com/unnc-ucc/Face2Multimodal).
![avatar](https://cn.bing.com/images/search?view=detailV2&ccid=I%2bnV30Vz&id=6685C63EAEE6B3CD27D2AEFBC9E255D85D453F0D&thid=OIP.I-nV30VzC5iAbOnLU2v3igHaDt&mediaurl=https%3a%2f%2fopengraph.githubassets.com%2f6de4c9fa08dfa058ca0016761f195c4838a773a02209bb1cbff035f2f8b9e49f%2funnc-ucc%2fFace2Statistics&exph=600&expw=1200&q=Face2Statistics&simid=607989901276223157&FORM=IRPRST&ck=853940CF2DFA527D6C7ED4518B836366&selectedIndex=1&ajaxhist=0&ajaxserp=0)

Jiaxin Tang
Introduction:
F2S is a roadmap for cost-effective information integration that fully fits the user experience. At present, most applications are used to collect skin conductively, heart rate and rate prediction for vehicle drivers.

Discussion(facial expression – mood have straight relationship?):
Facial expressions are one of the more important aspects of human communication. The face is responsible for communicating not only thoughts or ideas, but also emotions.(e.g., anger, disgust, fear, happy, sad, surprise, and to a lesser extent contempt, embarrassment, interest, pain, and shame) However, these emotion expressions are not immune to modification by social learning; different cultures learn different display rules to manage their expressions of emotion. At the same time, facial expressions are learned to be controlled and hidden.  The message generated by an emotion 
has to be captured instantaneously. The start, duration, and end of the movement are the stages that have to be taken into account. Involuntary and momentary expressions activate a particular muscular contraction, giving indications on the type of associated emotion. Positive emotions share a particular expression (e.g., the smile), which can be observed in terms of time, intensity, and context. Negative emotions (e.g., sadness) also exhibit a particular morphology of expression (e.g., 
corners of the mouth, eyebrows) characteristic of unhappy states. Some emotions are given no expression on the human face. This means we are unable to identify a facial expression, vocal expression, or bodily behavior associated with them – no 
discernible pattern or sign of distinction exists. This is a legacy of ontogeny and phylogeny. There is a template at the CNS level which is unique for the emotions. The fact that an emotion is not linguistically coded does not mean that the emotion does not exist. There can be emotion without facial expression. Research using EMG has detected alterations in the pattern of facial activity. Facial expressions are configurations of different micromotor (small muscle) movements in the face that are used to infer a person’s discrete emotional state (e.g., happiness, anger). Ekman and Friesen’s facial action coding system (FACS) was the first widely used and empirically validated approach to classifying a person’s emotional state from their facial expressions (Ekman, 1992; Ekman & Friesen, 1978). Finally, through some experiments, they came up with a measure of the participant's facial expressions.
In general, facial expressions are partly directly related to mood.
